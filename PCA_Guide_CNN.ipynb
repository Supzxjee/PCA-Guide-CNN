{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0794519f-171d-4e38-a3d0-4df95fb95d32",
      "metadata": {
        "id": "0794519f-171d-4e38-a3d0-4df95fb95d32"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "TARGET_DATASET = 'CK+'\n",
        "\n",
        "CONFIG = {\n",
        "    'CK+': {\n",
        "        'path': 'CK+48',           # ƒê∆∞·ªùng d·∫´n folder\n",
        "        'img_size': 48,\n",
        "        'batch_size': 32,\n",
        "        'epochs': 20,\n",
        "        'model_type': 'standard',  # D√πng model chu·∫©n\n",
        "        'test_split': 0.2          # T·ª± chia train/test\n",
        "    },\n",
        "    'JAFFE': {\n",
        "        'path': 'jaffe',\n",
        "        'img_size': 48,\n",
        "        'batch_size': 8,           # Batch nh·ªè cho data √≠t\n",
        "        'epochs': 60,              # Train l√¢u h∆°n\n",
        "        'model_type': 'compact',   # D√πng model nh·ªè g·ªçn\n",
        "        'test_split': 0.2\n",
        "    },\n",
        "    'FER2013': {\n",
        "        'path': 'fer2013',\n",
        "        'img_size': 48,\n",
        "        'batch_size': 64,          # Batch l·ªõn cho data nhi·ªÅu\n",
        "        'epochs': 30,\n",
        "        'model_type': 'standard',\n",
        "        'has_subfolders': True     # ƒê√£ c√≥ s·∫µn folder train/test ri√™ng\n",
        "    }\n",
        "}\n",
        "\n",
        "PCA_COMPONENTS = 0.95  # Gi·ªØ l·∫°i 95% th√¥ng tin\n",
        "\n",
        "def prepare_jaffe_sorting(base_path):\n",
        "    \"\"\"H√†m ri√™ng ƒë·ªÉ s·∫Øp x·∫øp file JAFFE n·∫øu ch∆∞a s·∫Øp x·∫øp\"\"\"\n",
        "    sorted_dir = base_path + '_sorted'\n",
        "    if os.path.exists(sorted_dir): return sorted_dir\n",
        "\n",
        "    print(f\"‚ö° [JAFFE] ƒêang s·∫Øp x·∫øp d·ªØ li·ªáu t·ª´ {base_path}...\")\n",
        "    emotion_mapping = {'AN': 'angry', 'DI': 'disgust', 'FE': 'fear',\n",
        "                       'HA': 'happy', 'NE': 'neutral', 'SA': 'sad', 'SU': 'surprise'}\n",
        "\n",
        "    if not os.path.exists(sorted_dir): os.makedirs(sorted_dir)\n",
        "\n",
        "    search_path = os.path.join(base_path, 'jaffe')\n",
        "    if not os.path.exists(search_path): search_path = base_path\n",
        "\n",
        "    count = 0\n",
        "    for filename in os.listdir(search_path):\n",
        "        if filename.endswith('.tiff') or filename.endswith('.tif'):\n",
        "            try:\n",
        "                code = filename.split('.')[1][:2]\n",
        "                if code in emotion_mapping:\n",
        "                    target = os.path.join(sorted_dir, emotion_mapping[code])\n",
        "                    if not os.path.exists(target): os.makedirs(target)\n",
        "                    shutil.copy(os.path.join(search_path, filename), os.path.join(target, filename))\n",
        "                    count += 1\n",
        "            except: pass\n",
        "    print(f\"‚úÖ ƒê√£ s·∫Øp x·∫øp {count} ·∫£nh v√†o {sorted_dir}\")\n",
        "    return sorted_dir\n",
        "\n",
        "def load_images_from_folder(path, img_size):\n",
        "    \"\"\"H√†m ƒë·ªçc ·∫£nh ƒë·ªá quy t·ª´ folder\"\"\"\n",
        "    print(f\"[INFO] ƒêang qu√©t folder: {path}\")\n",
        "    data, labels = [], []\n",
        "    if not os.path.exists(path):\n",
        "        print(f\"‚ùå Kh√¥ng t√¨m th·∫•y ƒë∆∞·ªùng d·∫´n: {path}\")\n",
        "        return np.array([]), np.array([]), []\n",
        "\n",
        "    classes = sorted([d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))])\n",
        "    print(f\"   -> Classes: {classes}\")\n",
        "\n",
        "    for idx, class_name in enumerate(classes):\n",
        "        class_path = os.path.join(path, class_name)\n",
        "        files = os.listdir(class_path)\n",
        "        for f in files:\n",
        "            try:\n",
        "                img = cv2.imread(os.path.join(class_path, f), cv2.IMREAD_GRAYSCALE)\n",
        "                if img is not None:\n",
        "                    img = cv2.resize(img, (img_size, img_size))\n",
        "                    data.append(img)\n",
        "                    labels.append(idx)\n",
        "            except: pass\n",
        "\n",
        "    data = np.array(data, dtype=\"float32\") / 255.0\n",
        "    data = np.expand_dims(data, axis=-1)\n",
        "    labels = to_categorical(np.array(labels), num_classes=len(classes))\n",
        "    return data, labels, classes\n",
        "\n",
        "def get_dataset(name):\n",
        "    \"\"\"H√†m ƒëi·ªÅu ph·ªëi vi·ªác t·∫£i d·ªØ li·ªáu d·ª±a tr√™n t√™n dataset\"\"\"\n",
        "    cfg = CONFIG[name]\n",
        "    path = cfg['path']\n",
        "\n",
        "    # 1. X·ª≠ l√Ω ri√™ng cho JAFFE (c·∫ßn sort tr∆∞·ªõc)\n",
        "    if name == 'JAFFE':\n",
        "        path = prepare_jaffe_sorting(path)\n",
        "        X, y, classes = load_images_from_folder(path, cfg['img_size'])\n",
        "        # Chia d·ªØ li·ªáu th·ªß c√¥ng v√¨ JAFFE kh√¥ng c√≥ folder train/test\n",
        "        X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "        X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
        "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), classes\n",
        "\n",
        "    # 2. X·ª≠ l√Ω ri√™ng cho FER2013 (ƒë√£ c√≥ folder train/test)\n",
        "    elif name == 'FER2013':\n",
        "        train_path = os.path.join(path, 'train')\n",
        "        test_path = os.path.join(path, 'test')\n",
        "\n",
        "        print(\"‚è≥ ƒêang t·∫£i t·∫≠p TRAIN...\")\n",
        "        X_train_full, y_train_full, classes = load_images_from_folder(train_path, cfg['img_size'])\n",
        "        print(\"‚è≥ ƒêang t·∫£i t·∫≠p TEST...\")\n",
        "        X_test, y_test, _ = load_images_from_folder(test_path, cfg['img_size'])\n",
        "\n",
        "        # T√°ch Validation t·ª´ Train (90-10)\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.1, random_state=42)\n",
        "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), classes\n",
        "\n",
        "    # 3. X·ª≠ l√Ω cho CK+ (G·ªôp chung r·ªìi chia)\n",
        "    else:\n",
        "        X, y, classes = load_images_from_folder(path, cfg['img_size'])\n",
        "        X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=cfg['test_split'], random_state=42)\n",
        "        X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), classes\n",
        "\n",
        "\n",
        "def build_model(input_shape, num_classes, model_type='standard'):\n",
        "    model = Sequential(name=f\"CNN_{model_type}\")\n",
        "\n",
        "    if model_type == 'compact': # D√†nh cho JAFFE\n",
        "        model.add(Conv2D(16, (3,3), activation='relu', padding='same', input_shape=input_shape))\n",
        "        model.add(MaxPooling2D((2,2)))\n",
        "        model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n",
        "        model.add(MaxPooling2D((2,2)))\n",
        "        model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
        "        model.add(MaxPooling2D((2,2)))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(64, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        lr = 0.0005\n",
        "    else: # D√†nh cho CK+, FER2013 (Standard)\n",
        "        model.add(Conv2D(32, (3,3), activation='relu', padding='same', input_shape=input_shape))\n",
        "        model.add(MaxPooling2D((2,2)))\n",
        "        model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
        "        model.add(MaxPooling2D((2,2)))\n",
        "        model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
        "        model.add(MaxPooling2D((2,2)))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(128, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        lr = 0.001\n",
        "\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.compile(optimizer=Adam(lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def plot_history_comparison(hist_A, hist_B, dataset_name):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Plot Accuracy\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(hist_A.history['val_accuracy'], 'r-o', label='Lu·ªìng A (G·ªëc)')\n",
        "    plt.plot(hist_B.history['val_accuracy'], 'b-s', label='Lu·ªìng B (PCA)')\n",
        "    plt.title(f'So s√°nh Accuracy ({dataset_name})')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Validation Accuracy')\n",
        "    plt.legend(); plt.grid(True)\n",
        "\n",
        "    # Plot Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(hist_A.history['val_loss'], 'r--', label='Lu·ªìng A Loss')\n",
        "    plt.plot(hist_B.history['val_loss'], 'b--', label='Lu·ªìng B Loss')\n",
        "    plt.title(f'So s√°nh Loss ({dataset_name})')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Validation Loss')\n",
        "    plt.legend(); plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(f\"üî∞ ƒêANG KH·ªûI CH·∫†Y CH·∫æ ƒê·ªò: {TARGET_DATASET}\")\n",
        "    cfg = CONFIG[TARGET_DATASET]\n",
        "\n",
        "    # 1. Load d·ªØ li·ªáu\n",
        "    (X_train, y_train), (X_val, y_val), (X_test, y_test), class_names = get_dataset(TARGET_DATASET)\n",
        "\n",
        "    if len(X_train) > 0:\n",
        "        print(f\"\\nüìä D·ªØ li·ªáu s·∫µn s√†ng: Train={len(X_train)}, Val={len(X_val)}, Test={len(X_test)}\")\n",
        "\n",
        "        # ---------------------------------------------------------\n",
        "        # üü¢ LU·ªíNG A: ·∫¢NH G·ªêC\n",
        "        # ---------------------------------------------------------\n",
        "        print(f\"\\nüöÄ [LU·ªíNG A] Train CNN tr√™n ·∫£nh g·ªëc ({cfg['epochs']} epochs)...\")\n",
        "        model_A = build_model((48,48,1), len(class_names), cfg['model_type'])\n",
        "        hist_A = model_A.fit(X_train, y_train, epochs=cfg['epochs'], batch_size=cfg['batch_size'],\n",
        "                             validation_data=(X_val, y_val), verbose=1)\n",
        "\n",
        "        # ---------------------------------------------------------\n",
        "        # üîµ LU·ªíNG B: PCA + CNN\n",
        "        # ---------------------------------------------------------\n",
        "        print(f\"\\nüöÄ [LU·ªíNG B] √Åp d·ª•ng PCA v√† Train...\")\n",
        "\n",
        "        # PCA Process\n",
        "        N, H, W, C = X_train.shape\n",
        "        pca = PCA(n_components=PCA_COMPONENTS)\n",
        "\n",
        "        print(\"   -> ƒêang fit PCA...\")\n",
        "        X_train_flat = X_train.reshape(N, -1)\n",
        "        pca.fit(X_train_flat)\n",
        "\n",
        "        print(\"   -> ƒêang transform d·ªØ li·ªáu...\")\n",
        "        # H√†m helper ƒë·ªÉ n√©n v√† t√°i t·∫°o\n",
        "        def pca_process(X_in, pca_model):\n",
        "            shape = X_in.shape\n",
        "            flat = X_in.reshape(shape[0], -1)\n",
        "            compressed = pca_model.transform(flat)\n",
        "            reconstructed = pca_model.inverse_transform(compressed)\n",
        "            return reconstructed.reshape(shape[0], 48, 48, 1)\n",
        "\n",
        "        X_train_pca = pca_process(X_train, pca)\n",
        "        X_val_pca = pca_process(X_val, pca)\n",
        "        X_test_pca = pca_process(X_test, pca)\n",
        "\n",
        "        model_B = build_model((48,48,1), len(class_names), cfg['model_type'])\n",
        "        hist_B = model_B.fit(X_train_pca, y_train, epochs=cfg['epochs'], batch_size=cfg['batch_size'],\n",
        "                             validation_data=(X_val_pca, y_val), verbose=1)\n",
        "\n",
        "        # ---------------------------------------------------------\n",
        "        # üèÜ ƒê√ÅNH GI√Å V√Ä L∆ØU\n",
        "        # ---------------------------------------------------------\n",
        "        print(\"\\nüîé K·∫æT QU·∫¢ SO S√ÅNH TR√äN T·∫¨P TEST:\")\n",
        "        acc_A = model_A.evaluate(X_test, y_test, verbose=0)[1]\n",
        "        acc_B = model_B.evaluate(X_test_pca, y_test, verbose=0)[1]\n",
        "\n",
        "        print(f\"‚úÖ Accuracy Lu·ªìng A (G·ªëc): {acc_A:.2%}\")\n",
        "        print(f\"‚úÖ Accuracy Lu·ªìng B (PCA): {acc_B:.2%}\")\n",
        "\n",
        "        # L∆∞u model v√† PCA\n",
        "        model_A.save(f'model_A_{TARGET_DATASET}.h5')\n",
        "        model_B.save(f'model_B_{TARGET_DATASET}.h5')\n",
        "        with open(f'pca_{TARGET_DATASET}.pkl', 'wb') as f: pickle.dump(pca, f)\n",
        "\n",
        "        # V·∫Ω bi·ªÉu ƒë·ªì\n",
        "        plot_history_comparison(hist_A, hist_B, TARGET_DATASET)\n",
        "\n",
        "    else:\n",
        "        print(\"‚ùå L·ªói: Kh√¥ng t·∫£i ƒë∆∞·ª£c d·ªØ li·ªáu.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}